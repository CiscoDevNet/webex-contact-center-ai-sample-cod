syntax = "proto3";

package com.cisco.wcc.ccai;

import  "suggestions.proto";
import  "recognize.proto";
import  "messages.proto";

// Role of the Stream
enum Role {

  ROLE_UNSPECIFIED = 0;
  HUMAN_AGENT = 1;
  AUTOMATED_AGENT = 2;
  END_USER = 3;
}

// Audio Encoding
enum AudioEncoding {
  // Not specified.
  ENCODING_UNSPECIFIED = 0;
  // Uncompressed 16-bit signed little-endian samples (Linear PCM).
  LINEAR16 = 1; // TODO : Do we still need this, if not remove.
  // 8-bit samples that compound 14-bit audio samples using G.711 PCMU/mu-law.
  MULAW = 2;
}

// Recognition Config
message RecognitionConfig {
  AudioEncoding encoding = 1;
  int32 sample_rate_hertz = 2;
  string language_code = 3;
}

// A wrapper of repeated TelephonyDtmf digits.
message DtmfEvents {
  // A sequence of TelephonyDtmf digits.
  repeated Dtmf dtmf_events = 1;
}

// [DTMF](https://en.wikipedia.org/wiki/Dual-tone_multi-frequency_signaling)
// digit in Telephony Gateway.
enum Dtmf {
  // Not specified. This value may be used to indicate an absent digit.
  TELEPHONY_DTMF_UNSPECIFIED = 0;

  // Number: '1'.
  DTMF_ONE = 1;

  // Number: '2'.
  DTMF_TWO = 2;

  // Number: '3'.
  DTMF_THREE = 3;

  // Number: '4'.
  DTMF_FOUR = 4;

  // Number: '5'.
  DTMF_FIVE = 5;

  // Number: '6'.
  DTMF_SIX = 6;

  // Number: '7'.
  DTMF_SEVEN = 7;

  // Number: '8'.
  DTMF_EIGHT = 8;

  // Number: '9'.
  DTMF_NINE = 9;

  // Number: '0'.
  DTMF_ZERO = 10;

  // Letter: 'A'.
  DTMF_A = 11;

  // Letter: 'B'.
  DTMF_B = 12;

  // Letter: 'C'.
  DTMF_C = 13;

  // Letter: 'D'.
  DTMF_D = 14;

  // Asterisk/star: '*'.
  DTMF_STAR = 15;

  // Pound/diamond/hash/square/gate/octothorpe: '#'.
  DTMF_POUND = 16;
}


// Agent Assist Request Object
message StreamingAnalyzeAAContentRequest {
  oneof InputData {
    bytes audio = 1;
    string text = 2;
  }

  // InputAudio Recognition Config
  RecognitionConfig inputAudioConfig = 3;

  // Default = True
  bool interim_results = 4;

  // Default = False
  bool single_utterance = 5;

  //  Unique Call Identifier
  string conversationId = 6;

  // conversationId + StreamId can form the global unique Id for tracking stream
  string roleId = 7;

  // Indicates the global config id for services.
  string ccaiConfigId = 8;

  // Only Caller Role is possible here.
  Role role = 9;

  // Map to capture any additional or miscellaneous info. All provider specific config will be passed in this Map.
  // These attributes will be configurable in the Developer tool, which can be added as supported by Provider.
  map<string, string> additionalInfo = 10;

  // OrgId for supporting OrgId based access
  string orgId = 11;
}

// Agent Answers Response Object
message StreamingAnalyzeAAContentResponse {
  // Recognition result of the user utterances.
  StreamingRecognitionResult  recognition_result = 1 ;

  // Response object of Agent Answers
  AgentAnswerResult agentAnswerResult = 2;

  // All other Misc info about message
  Message message = 3;
}

// Features to be offered on the Virtual Agent Request
message VAFeatures {

  // Whether to enable sentiment ananlysis on Audio
  bool enableSentiments = 1;

  // Other features like Voice Biometric Authentication, Translation, Language Identification etc to be added here.
}


// Virtual Agent Request Object
message StreamingAnalyzeVAContentRequest {

  // Input Data here can be Audio / text or DTMF
  oneof InputData {
    bytes audio = 1;
    string text = 2;
    DtmfEvents dtmf = 3;
  }

  // InputAudio Recognition Config
  RecognitionConfig inputAudioConfig = 4;

  // Default = False for Virtual Assistant
  bool interim_results = 5;

  // Default = True
  bool single_utterance = 6;

  //  Unique Call Identifier
  string conversationId = 7;

  // conversationId + StreamId can form the global unique Id for tracking stream
  string roleId = 8;

  // Indicates the global config id for services.
  string ccaiConfigId = 9;

  // Only Caller Role is possible here.
  Role role = 10;

  // Map to capture any additional or miscellaneous info. All provider specific config will be passed in this Map.
  // These attributes will be configurable in the Developer tool, which can be added as supported by Provider.
  map<string, string> additionalInfo = 11;

  // OrgId for supporting OrgId based access
  string orgId = 12;

  // All the Features which needs to be offered in the responses.
  VAFeatures features = 13;
}

// Virtual Agent Message Object
// Contents TBD
message VAMessage {
  // Text text = 1;
  //  google.protobuf.Struct payload = 2;
  //  Struct live_agent_handoff = 1;
  //  bool end_interaction = 2;
  // string audio_uri = 3;
}

message VirtualAgentReply {
  // Provider specific message object, in the form of JSON.
}

// Virtual Agent Response Object
message StreamingAnalyzeVAContentResponse {
  // Recognition result of the user utterances.
  StreamingRecognitionResult  recognition_result = 1;

  // Response object of VirtualAgent. Contains provider specific Payload.
  VirtualAgentReply va_result = 2;

  // All other Misc info about message
  Message message = 3;

  // Text returned by Virtual Agent to be played to caller
  string reply_text = 4;

  // Audio returned by Virtual Agent to be played to caller
  bytes reply_audio = 5;

  // Virtual Agent Message Object. Returns the dialog specfic generic response.
  VAMessage va_message = 6;

  // Intent identfied from the user utterance
  string intent = 7;

}

service AnalyzeContentService {

  // Bi-Directional Streaming API for Agent Assist
  rpc StreamingAnalyzeAAContent(stream StreamingAnalyzeAAContentRequest) returns (stream StreamingAnalyzeAAContentResponse) {}


  //Bi-Directional Streaming API for Virtual Agent
  rpc StreamingAnalyzeVAContent(stream StreamingAnalyzeVAContentRequest) returns (stream StreamingAnalyzeVAContentResponse) {}

}

