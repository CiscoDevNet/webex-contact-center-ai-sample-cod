syntax = "proto3";

package com.cisco.wcc.ccai;



// A streaming speech recognition result corresponding to a portion of the audio
// that is currently being processed.
message StreamingRecognitionResult {
  // Output only. May contain one or more recognition hypotheses (up to the
  // maximum specified in `max_alternatives`).
  // These alternatives are ordered in terms of accuracy, with the top (first)
  // alternative being the most probable, as ranked by the recognizer.
  repeated SpeechRecognitionAlternative alternatives = 1;

  // Output only. If `false`, this `StreamingRecognitionResult` represents an
  // interim result that may change. If `true`, this is the final time the
  // speech service will return this particular `StreamingRecognitionResult`,
  // the recognizer will not return any further hypotheses for this portion of
  // the transcript and corresponding audio.
  bool is_final = 2;

  // Output only. Time offset of the end of this result relative to the
  // beginning of the audio.
  Duration result_end_time = 4;

  // For multi-channel audio, this is the channel number corresponding to the
  // recognized result for the audio from that channel.
  // For audio_channel_count = N, its output values can range from '1' to 'N'.
  int32 channel_tag = 5;

  // Output only. The
  // [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag of the
  // language in this result. This language code was detected to have the most
  // likelihood of being spoken in the audio.
  string language_code = 6;

  // Whether or not recording offsets have been applied to the word
  // alignment values. Otherwise the word alignment start and end times
  // are only relative within the utterance.
  bool has_applied_recording_offsets = 7;

  // Zero or more integers representing the speaker ID of this
  // result. This is usually derived from the speaker integers
  // that are passed in the streaming request.
  repeated uint32 speaker_ids = 8;

  // The unix time in miliseconds which was received from the client
  // for the StreamingRecognizeRequest that was last used to complete
  // this utterance.
  int64 last_packet_metrics_unix_timestamp_ms = 9;

  string message_type = 10;
}

// Alternative hypotheses (a.k.a. n-best list).
message SpeechRecognitionAlternative {
  // Output only. Transcript text representing the words that the user spoke.
  string transcript = 1;

  // Output only. The confidence estimate between 0.0 and 1.0. A higher number
  // indicates an estimated greater likelihood that the recognized words are
  // correct. This field is set only for the top alternative of a non-streaming
  // result or, of a streaming result where `is_final=true`.
  // Not yet supported.
  float confidence = 2;

  // Output only. A list of word-specific information for each recognized word.
  // Note: When `enable_speaker_diarization` is true, you will see all the words
  // from the beginning of the audio.
  repeated WordInfo words = 3;
}

// Word-specific information for recognized words.
message WordInfo {
  // Output only. Time offset relative to the beginning of the audio,
  // and corresponding to the start of the spoken word.
  // This field is only set if `enable_word_time_offsets=true` and only
  // in the top hypothesis.
  // This is an experimental feature and the accuracy of the time offset can
  // vary.
  Duration start_time = 1;

  // Output only. Time offset relative to the beginning of the audio,
  // and corresponding to the end of the spoken word.
  // This field is only set if `enable_word_time_offsets=true` and only
  // in the top hypothesis.
  // This is an experimental feature and the accuracy of the time offset can
  // vary.
  Duration end_time = 2;

  // Output only. The word corresponding to this set of information.
  string word = 3;
}

message Duration {
  // Signed seconds of the span of time. Must be from -315,576,000,000
  // to +315,576,000,000 inclusive. Note: these bounds are computed from:
  // 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years
  int64 seconds = 1;

  // Signed fractions of a second at nanosecond resolution of the span
  // of time. Durations less than one second are represented with a 0
  // `seconds` field and a positive or negative `nanos` field. For durations
  // of one second or more, a non-zero value for the `nanos` field must be
  // of the same sign as the `seconds` field. Must be from -999,999,999
  // to +999,999,999 inclusive.
  int32 nanos = 2;
}

message Status {
  // The status code, which should be an enum value of
  // [google.rpc.Code][google.rpc.Code].
  int32 code = 1;

  // A developer-facing error message, which should be in English. Any
  // user-facing error message should be localized and sent in the
  // [google.rpc.Status.details][google.rpc.Status.details] field, or localized
  // by the client.
  string message = 2;
}
